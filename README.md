# Predi√ß√£o de Idade Estelar utilizando Modelos de Regress√£o

Este reposit√≥rio cont√©m o desenvolvimento de um pipeline de Machine Learning focado na predi√ß√£o cont√≠nua da idade de estrelas. O projeto utiliza dados astrof√≠sicos provenientes do cat√°logo VizieR para treinar, validar e otimizar algoritmos de regress√£o, mapeando a rela√ß√£o n√£o-linear entre as propriedades estelares e seu est√°gio evolutivo.

## üéØ Objetivo do Projeto
Desenvolver um modelo preditivo de alta precis√£o para estimar a idade estelar e, por meio de infer√™ncia algor√≠tmica (Feature Importance), validar as vari√°veis astrof√≠sicas de maior impacto na evolu√ß√£o estelar.

## üìä Conjunto de Dados
Os dados foram extra√≠dos do cat√°logo VizieR e cont√™m as seguintes *features* independentes (vari√°veis preditoras):
* `Mass`: Massa estelar.
* `logL`: Logaritmo da Luminosidade.
* `log.Teff`: Logaritmo da Temperatura Efetiva.
* `B-V`: √çndice de Cor.
* `Vmag`: Magnitude Visual Absoluta/Aparente.
* **Vari√°vel Alvo (Target):** `Age` (Idade).

## ‚öôÔ∏è Metodologia e Modelagem Predita

O projeto seguiu uma abordagem evolutiva na complexidade dos modelos de regress√£o, utilizando a m√©trica **RMSE (Root Mean Squared Error)** para avalia√ß√£o de desempenho e controle de generaliza√ß√£o. Os dados foram divididos em conjuntos de treino e teste (70/30) utilizando o `train_test_split`.

### 1. Modelo Param√©trico (Baseline)
* **Algoritmo:** Linear Regression
* **Desempenho (Teste RMSE):** `1.40`
* **An√°lise:** O erro elevado evidenciou que os pressupostos de linearidade n√£o s√£o adequados para representar a complexidade das rela√ß√µes f√≠sicas da evolu√ß√£o estelar.

### 2. Modelo N√£o-Param√©trico (Controle de Vari√¢ncia)
* **Algoritmo:** Decision Tree Regressor
* **Desempenho Inicial (Sem poda):** RMSE Treino `0.10` | RMSE Teste `0.72` (*Alto Overfitting*)
* **Otimiza√ß√£o (Hyperparameter Tuning):** Ap√≥s ajustar o hiperpar√¢metro `max_depth=7` para limitar o crescimento da √°rvore e for√ßar a generaliza√ß√£o, o modelo alcan√ßou uma performance mais robusta.
* **Desempenho Otimizado:** RMSE Treino `0.39` | RMSE Teste `0.68`

### 3. Modelo de Ensemble (Arquitetura Final)
* **Algoritmo:** Random Forest Regressor (`n_estimators=100`)
* **Desempenho Final:** RMSE Treino `0.19` | RMSE Teste `0.55`
* **An√°lise:** A agrega√ß√£o de m√∫ltiplas √°rvores reduziu drasticamente a vari√¢ncia do modelo isolado, atingindo o menor erro preditivo do projeto e estabilizando as predi√ß√µes para dados n√£o vistos.

## üîç Extra√ß√£o de Insights: Import√¢ncia das Vari√°veis (Feature Importance)

A abstra√ß√£o matem√°tica do algoritmo Random Forest permitiu extrair o peso de cada vari√°vel na redu√ß√£o das impurezas dos n√≥s (Feature Importance). Os resultados validam conceitos fundamentais da astrof√≠sica:

| Vari√°vel | Import√¢ncia (%) | Interpreta√ß√£o F√≠sica |
| :--- | :--- | :--- |
| **`Mass`** | 67.4% | Principal determinante da vida estelar. Dita a taxa de fus√£o nuclear. |
| **`logL`** | 16.5% | Indicador crucial do est√°gio evolutivo (ex: sa√≠da da Sequ√™ncia Principal). |
| **`log.Teff`**| 13.9% | Mensura√ß√£o de temperatura correlacionada √† evolu√ß√£o no Diagrama HR. |
| **`B-V`** | 1.3% | Redundante, pois a vari√¢ncia j√° √© capturada pelo `log.Teff`. |
| **`Vmag`** | 0.8% | Redundante em rela√ß√£o ao `logL`. |

*(Adicione aqui a imagem do gr√°fico gerado no projeto: `![Gr√°fico de Feature Importance](caminho_para_a_imagem.png)`)*

## üõ†Ô∏è Tecnologias e Bibliotecas Utilizadas
* **Linguagem:** Python 3
* **Manipula√ß√£o de Dados:** `pandas`, `numpy`
* **Visualiza√ß√£o:** `matplotlib`, `seaborn`
* **Machine Learning:** `scikit-learn` (`LinearRegression`, `DecisionTreeRegressor`, `RandomForestRegressor`, `train_test_split`, m√©tricas de erro)
